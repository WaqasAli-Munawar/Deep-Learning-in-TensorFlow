{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab769047",
   "metadata": {},
   "source": [
    "In a previous file, we learned about the importance of weight initialization. So far we've learned about different weight initializers in our models which randomly select the initial weight values from a distribution, such as the normal distribution. As our model trains, it updates those weights across all of its layers.\n",
    "\n",
    "During each training step, the weights in a convolutional layer update, enabling the kernels of that layer to extract relevant features from the input more effectively. Similarly, the weights in a fully-connected layer update over each training step, improving the layer's ability to classify features from the convolutional layers into specific classes.\n",
    "\n",
    "A trained model consists of multiple layers, with each layer storing specific weights that enable the model to perform a particular task, such as classification. These weights are carefully calculated during the training process and are essential for the model's ability to make accurate predictions.\n",
    "\n",
    "Let's say we trained a model on the [ImageNet dataset](https://en.wikipedia.org/wiki/ImageNet), which contains millions of images across 1000 categories, such as birds, fruits, vehicles, and even household objects like salt shakers. A model trained on such a dataset with reasonably high accuracy would've learned weights that could extract features across all those categories!\n",
    "\n",
    "What if we initialized the weights of the convolutional layers of a new model using the weights of a model trained on ImageNet?\n",
    "\n",
    "That's the basis of **transfer learning**. Instead of creating our own model and letting it train on a dataset to learn those weights, we use the weights from a model that has already been trained on a dataset like ImageNet. The already trained model is called a **pre-trained model**.\n",
    "\n",
    "The pre-trained model has already learned to extract a wide variety of features. We can transfer the knowledge it has gained to a new model and use that knowledge to attempt to solve a similar problem on a different dataset.\n",
    "\n",
    "We start the transfer learning process by creating a new model that's based on a pre-trained model. For example, we could create a new model based on the ResNet18 architecture that's been pre-trained on ImageNet. Our new model would have the same layers and weights as that of the pre-trained model. We could then train the new model on our dataset, like the [Fruits-360 dataset](https://github.com/Horea94/Fruit-Images-Dataset).\n",
    "\n",
    "However, that presents us with two problems.\n",
    "\n",
    "First problem: The Fruits-360 dataset only has `131` classes. The pre-trained model, trained on ImageNet, was trained on `1000` classes. We'd have to modify the final output layer of our new model so it outputs only `131` values, not `1000`.\n",
    "\n",
    "Second problem: The weights of the pre-trained model are capable of extracting features from a wide variety of classes. We want to rely on the knowledge stored in those weights. If we re-trained our new model on our new dataset, those weights would get updated and we could potentially lose all that valuable knowledge gained by the pre-trained model. To solve this, we freeze the weights in the convolutional layers of the model.\n",
    "\n",
    "Freezing the layers would ensure that those weights don't get updated as the new model trains on our new dataset. We only train the fully-connected layers of the model since those layers are responsible for taking in the features from the convolutional layers and then classifying those features.\n",
    "\n",
    "Here's a simplified representation of the above workflow:\n",
    "\n",
    "![](https://s3.amazonaws.com/dq-content/783/1.1-m783.svg)\n",
    "\n",
    "In this file, we'll learn to implement each step of this workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c0b04a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "471eef3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 67692 files belonging to 131 classes.\n",
      "Using 50769 files for training.\n",
      "Found 67692 files belonging to 131 classes.\n",
      "Using 16923 files for validation.\n",
      "Found 22688 files belonging to 131 classes.\n"
     ]
    }
   ],
   "source": [
    "train_set = tf.keras.utils.image_dataset_from_directory(\n",
    "    directory='fruits/train',\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=256,\n",
    "    image_size=(100, 100),\n",
    "    validation_split=0.25,\n",
    "    subset=\"training\",\n",
    "    seed=417)\n",
    "\n",
    "validation_set = tf.keras.utils.image_dataset_from_directory(\n",
    "    directory='fruits/train',\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=256,\n",
    "    image_size=(100, 100),\n",
    "    validation_split=0.25,\n",
    "    subset=\"validation\",\n",
    "    seed=417)\n",
    "\n",
    "test_set = tf.keras.utils.image_dataset_from_directory(\n",
    "    directory='fruits/test',\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=256,\n",
    "    image_size=(100, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d919c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = layers.Rescaling(1/255)\n",
    "\n",
    "train_set_normalized = train_set.map(lambda x, y: (normalization_layer(x), y))\n",
    "validation_set_normalized = validation_set.map(lambda x, y: (normalization_layer(x), y))\n",
    "test_set_normalized = test_set.map(lambda x, y: (normalization_layer(x), y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440ed89f",
   "metadata": {},
   "source": [
    "The first step of our transfer learning process will be to create a new model using a pre-trained model. Thankfully, TensorFlow has several pre-trained models that we can access using the [`tensorflow.keras.applications` module](https://keras.io/api/applications/).\n",
    "\n",
    "For this file, we'll use a ResNet50 model that was pre-trained on a subset of ImageNet. There are some differences between the ResNet18 and ResNet50 architectures. The latter has more residual blocks, and each residual block has more convolutional layers compared to the former. ResNet50 uses a model architecture that looks like this:\n",
    "\n",
    "![](https://s3.amazonaws.com/dq-content/783/3.1-m783.svg)\n",
    "\n",
    "The above is a simplified representation of the architecture. Each residual block contains three convolutional layers, and each residual block is repeated a certain number of times. For example, the first residual block is repeated `3` times, the second one is repeated `4` times, and so on.\n",
    "\n",
    "One of the good things about transfer learning is that we don't always need to fully understand the pre-trained model's architecture. If you'd like more details, you're encouraged to check out [ResNet50's architecture](https://arxiv.org/abs/1512.03385).\n",
    "\n",
    "We can create the `base model`, an instance of the pre-trained model, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efe7e218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import applications\n",
    "\n",
    "base_model = applications.resnet50.ResNet50(include_top=False,weights='imagenet',input_shape=(100, 100, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa25c6d",
   "metadata": {},
   "source": [
    "Where:\n",
    "\n",
    "-   `include_top` refers to whether or not we want to include the fully-connected layers of the model. The word \"top\" might seem counterintuitive, but it's just an old naming convention used to refer to those layers.\n",
    "    \n",
    "-   `weights` refers to which weights we want to load in for our model. By setting it to `'imagenet'`, we indicate that we want the model to be loaded in with weights of a ResNet50 model that was trained on ImageNet.\n",
    "    \n",
    "-   `input_shape` is the shape of the input images we plan to input into our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39292419",
   "metadata": {},
   "source": [
    "The base model we created on the above includes all layers from ResNet50 except the fully-connected layers. We need to add those next. Before we do that, we need to make sure that the weights of our convolutional layers don't get updated during training. In other words, we'll need to freeze those layers.\n",
    "\n",
    "Models in TensorFlow/Keras have an attribute called `trainable`. We can set this attribute to either `True` or `False` depending on whether we want the model to be trainable. Since our `base_model` only contains convolutional layers so far, we can freeze the entire model by setting this attribute to `False`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b8699eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987d32c0",
   "metadata": {},
   "source": [
    "After that, we can add the fully-connected layers to our base model. The process for this is similar to how we would create a model using TensorFlow's Functional API.\n",
    "\n",
    "We first create an [Input layer](https://www.tensorflow.org/api_docs/python/tf/keras/layers/InputLayer).\n",
    "\n",
    "A model in Keras has a [call() method](https://www.tensorflow.org/api_docs/python/tf/keras/Model#call) that allows us to call the model as a function. We can use the `call()` method and call `base_model` as a function after creating the input layer. The function call takes in:\n",
    "\n",
    "-   The input layer\n",
    "    \n",
    "-   A parameter called `training`, set to `False`\n",
    "    \n",
    "\n",
    "ResNet50 contains a lot of batch normalization layers. The batch normalization layers only calculate the mean and variance values of each batch of data.\n",
    "\n",
    "Although those values are not something the model learns, they do get updated when we train our model on the new dataset because the batches of images it will train on will be different than those used initially to train our base model.\n",
    "\n",
    "When we train our new model, we don't want those values to get updated as well. Setting `training` to `False` ensures that.\n",
    "\n",
    "This is what our function call would look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18fe657e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model, Input\n",
    "\n",
    "input_layer = Input(shape=(100, 100, 3))\n",
    "features_layer = base_model(input_layer, training=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc944310",
   "metadata": {},
   "source": [
    "The function call will create a layer that acts as a reference to our base model. We can then flatten this layer and add some fully-connected layers on top of it. Or we could instead apply a global average pooling layer, followed by an output layer. That's a design choice we can make as we see fit. In this file, we'll use a global average pooling layer.\n",
    "\n",
    "We can then instantiate a model using the [`Model() class`](https://www.tensorflow.org/api_docs/python/tf/keras/Model) by passing in the input and output layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cb89710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ resnet50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)          │      <span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling2d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">131</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">268,419</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ resnet50 (\u001b[38;5;33mFunctional\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m2048\u001b[0m)          │      \u001b[38;5;34m23,587,712\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling2d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m131\u001b[0m)                 │         \u001b[38;5;34m268,419\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,856,131</span> (91.00 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m23,856,131\u001b[0m (91.00 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">268,419</span> (1.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m268,419\u001b[0m (1.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> (89.98 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m23,587,712\u001b[0m (89.98 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "global_pooling = layers.GlobalAveragePooling2D()(features_layer)\n",
    "output = layers.Dense(131)(global_pooling)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ab999a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1191s\u001b[0m 6s/step - accuracy: 0.0079 - loss: 4.8997 - val_accuracy: 0.0206 - val_loss: 4.8138\n",
      "Epoch 2/3\n",
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1180s\u001b[0m 6s/step - accuracy: 0.0172 - loss: 4.7992 - val_accuracy: 0.0185 - val_loss: 4.7661\n",
      "Epoch 3/3\n",
      "\u001b[1m156/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m3:10\u001b[0m 4s/step - accuracy: 0.0225 - loss: 4.7545"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m loss \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mCategoricalCrossentropy(from_logits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mopt, loss\u001b[38;5;241m=\u001b[39mloss, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m----> 5\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(train_set_normalized, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39mvalidation_set_normalized)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:314\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    313\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 314\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[0;32m    315\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[0;32m    316\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    879\u001b[0m     args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n\u001b[0;32m    880\u001b[0m )\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[0;32m    255\u001b[0m     )\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m   1501\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1502\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   1503\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[0;32m   1504\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[0;32m   1505\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1506\u001b[0m   )\n\u001b[0;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1515\u001b[0m   )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "opt = tf.keras.optimizers.SGD()\n",
    "loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "model.compile(optimizer=opt, loss=loss, metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_set_normalized, epochs=3, validation_data=validation_set_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401cc87a",
   "metadata": {},
   "source": [
    "### Preprocessing the Input\n",
    "\n",
    "Our pre-trained model is performing very poorly on our new dataset. The reason for this is that our pre-trained model was trained on a completely different dataset than the one we're using. In particular, the dataset it used was preprocessed in a particular way.\n",
    "\n",
    "In a last file, we learned that the validation and test datasets should be preprocessed similarly to the training dataset. Similarly, when we use a pre-trained model, we need to preprocess our new training data the same way the pre-trained model's original training data was preprocessed. The same preprocessing is applied to all the datasets — the training, validation, and test sets.\n",
    "\n",
    "We need to make sure that we perform the same preprocessing that was performed on ImageNet to the `Fruits-360` dataset. The [ResNet50 documentation](https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet50/ResNet50) points out the kind of preprocessing it used:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e3b937",
   "metadata": {},
   "source": [
    "`resnet.preprocess_input will convert the input images from RGB to BGR, then will zero-center each color channel with respect to the ImageNet dataset, without scaling.`\n",
    "\n",
    "The conversion of RGB to BGR implies that the red and blue input channels are swapped. The following visual depicts the differences between the preprocessing we applied earlier in this file and the preprocessing that we required:\n",
    "\n",
    "![](https://s3.amazonaws.com/dq-content/783/preprocessed_images.png)\n",
    "\n",
    "The above images were generated using Matplotlib. The original image has pixel values between `0` and `255` and are all integers. The rescaled image has pixel values between `0.0` and `1.0` and are all floats. Because of how Matplotlib displays those two ranges of values, the images appear the same, even though their pixel values are different. The third image is preprocessed using the same preprocessing that was applied to ImageNet. We can see how different it really is to our rescaled image. No wonder we weren't getting good results!\n",
    "\n",
    "TensorFlow provides us with a function to apply the ImageNet preprocessing on our dataset. We can call the function, [`tensorflow.keras.applications.resnet50.preprocess_input()`](https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet50/preprocess_input), on our input layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe4406a",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_input_layer = applications.resnet50.preprocess_input(input_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd216d9",
   "metadata": {},
   "source": [
    "By calling the function on the input layer, we don't have to preprocess our datasets individually. The function call will be part of our model and be automatically applied to the datasets. Since we're preprocessing the input via this layer, we don't have to normalize the datasets like we did after loading in the data as we did earlier in this file.\n",
    "\n",
    "This is the reason why we set the `training` argument to `False` when we call our `base_model()` function. The frozen batch normalization layers store information related to the original, preprocessed training data. We don't want that information to be overwritten or updated when we train our new model. Setting the `training` parameter to `False` ensures that doesn't happen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1797e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_layer = base_model(preprocessed_input_layer, training=False)\n",
    "global_pooling = layers.GlobalAveragePooling2D()(features_layer)\n",
    "output = layers.Dense(131)(global_pooling)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1068f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.SGD()\n",
    "loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "model.compile(optimizer=opt, loss=loss, metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_set, epochs=3, validation_data=validation_set)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_set)\n",
    "print(f\"Test set accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d2f5bb",
   "metadata": {},
   "source": [
    "###  Fine-tuning the Model\n",
    "\n",
    "Our new model is performing quite well! In the previous file, our ResNet18 model achieved a validation accuracy of `~99%` and a test set accuracy of `~95%` after training for `5` epochs. Our transfer learning approach, with a pre-trained ResNet50 model, achieved a validation accuracy of `~98%` and a test set accuracy of `~92%` after training for just `3` epochs!\n",
    "\n",
    "We didn't even have to worry about implementing 50 layers ourselves or about implementing our own architecture. What's especially surprising is how well the model performs, given ImageNet does not contain the same classes as `Fruits-360`. The pre-trained weights were still able to extract relevant features from the latter dataset.\n",
    "\n",
    "This is the magic of transfer learning!\n",
    "\n",
    "### Fine-tuning\n",
    "\n",
    "However, we might not always be this lucky. There might be instances where our dataset might be too different to the one the pre-trained model was trained upon, or our dataset might be too small. We could end up with a relatively poorly performing model.\n",
    "\n",
    "In such a situation, we could try to fine-tune our model. Fine-tuning our model involves unfreezing the convolutional layers of our base model, then re-training it.\n",
    "\n",
    "This allows the pre-trained weights to update based on the new dataset. While this could be helpful, we also don't want the pre-trained weights to change so drastically that the model performs even worse. To account for that, when we re-train the model, we'll choose a very small learning rate. The small learning rate ensures that the weights only get updated by small amounts.\n",
    "\n",
    "In the following exercise, we'll unfreeze `base_model`, then retrain `model`. We don't have to modify `model` in any way because it was created off of `base_model`. The changes applied to `base_model` internally affect `model` as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f1b951",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = True\n",
    "\n",
    "opt = tf.keras.optimizers.SGD(learning_rate=0.0001)\n",
    "loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "model.compile(optimizer=opt, loss=loss, metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_set, epochs=5, validation_data=validation_set)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_set)\n",
    "print(f\"Test set accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fbcfc7",
   "metadata": {},
   "source": [
    "### Transfer Learning on the Beans Dataset I\n",
    "\n",
    "Fine-tuning our model did improve its performance; the validation accuracy came out to `~99%` and the test set accuracy was `~94%`. We could always experiment more if we wanted to. But for now, let's revisit the [beans dataset](https://github.com/AI-Lab-Makerere/ibean/) we worked with earlier in the file. We'll use transfer learning to see whether we can improve upon our previous results.\n",
    "\n",
    "The `beans` dataset has only `1034` images in the training set and `133` in the validation set. We noticed that our models would either overfit on the training set or not perform too well when we added some regularization.\n",
    "\n",
    "The `beans` dataset consists of images of dimensions `(500, 500, 3)`. ResNet50 is a fairly large model. It would take a powerful GPU with a lot of memory to be able to handle model training. As mentioned in earlier files, trying to train complex models on large images can often result in Out of Memory (OOM) errors.\n",
    "\n",
    "To circumvent such errors, we can either try to use a smaller model, or we could reduce the image dimensions. We'll opt for the latter and resize the bean plant images to `(100, 100, 3)` to match our model's expected input dimensions.\n",
    "\n",
    "Given the complexity of the pre-trained model, and the small size of the `beans` dataset, there's a significant chance of the model overfitting. To counter that, we'll add a data augmentation layer to our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92914940",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_train_set = tf.keras.utils.image_dataset_from_directory(\n",
    "    directory='beans/train/',\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=128,\n",
    "    image_size=(100, 100))\n",
    "\n",
    "b_validation_set = tf.keras.utils.image_dataset_from_directory(\n",
    "    directory='beans/validation/',\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=128,\n",
    "    image_size=(100, 100))\n",
    "\n",
    "b_test_set = tf.keras.utils.image_dataset_from_directory(\n",
    "    directory='beans/test/',\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=128,\n",
    "    image_size=(100, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1b3796",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = applications.resnet50.ResNet50(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=(100, 100, 3))\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "input_layer = Input(shape=(100, 100, 3))\n",
    "preprocessed_input_layer = applications.resnet50.preprocess_input(input_layer)\n",
    "augmentation_layer = layers.RandomFlip(mode=\"horizontal_and_vertical\")(preprocessed_input_layer)\n",
    "features_layer = base_model(augmentation_layer, training=False)\n",
    "global_pooling = layers.GlobalAveragePooling2D()(features_layer)\n",
    "output = layers.Dense(3)(global_pooling)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output)\n",
    "\n",
    "opt = tf.keras.optimizers.Adam()\n",
    "loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "model.compile(optimizer=opt, loss=loss, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(b_train_set, epochs=20, validation_data=b_validation_set)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfbb96d",
   "metadata": {},
   "source": [
    "Our model is doing quite well on the `beans` dataset. Even with just `20` epochs, it's performing better than our models in the previous files. Next, we'll try to fine-tune our model.\n",
    "\n",
    "![](https://s3.amazonaws.com/dq-content/783/8.0-m783.png)\n",
    "\n",
    "With the `Fruits-360` dataset, we unfroze all the layers of our base model. With a dataset as large as `Fruits-360`, fine-tuning over all ResNet50 layers is a reasonable choice. However, we don't always need to unfreeze the entire base model.\n",
    "\n",
    "We can choose to unfreeze only a select few layers and fine-tune our model on just those layers. For a small dataset, it's recommended to unfreeze the last few layers and fine-tune the model on them in order to avoid overfitting. Depending on the model's performance, we can repeat the process for other layers as well, if needed.\n",
    "\n",
    "We'll unfreeze the last residual block of the base model. According to this [research paper](https://arxiv.org/abs/1512.03385), the final residual block of the model contains three convolutional layers. Similar to ResNet18, the first two layers in the block are followed by batch normalization and ReLU layers. The third layer is followed by a batch normalization layer. The input to the block is added to the output of the third layer, using an Add layer, and that output is followed by a ReLU layer.\n",
    "\n",
    "That's a total of `10` layers in the last block, including the Add layer.\n",
    "\n",
    "In TensorFlow, we can access the layers of a model using the `layers` attribute. We can then iterate over the layers to freeze or unfreeze any layer:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "64471c0e",
   "metadata": {},
   "source": [
    "for layer in model.layers:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc1a5c3",
   "metadata": {},
   "source": [
    "If we wanted to access only the last `10` layers of a model, we could slice it like we would a Python list:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16c9320",
   "metadata": {},
   "source": [
    "`model.layers[-10:]`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1fc7f6",
   "metadata": {},
   "source": [
    "In TensorFlow, if we want to unfreeze specific layers, we need to perform the following two steps:\n",
    "\n",
    "-   Unfreeze the entire model.\n",
    "    \n",
    "-   Freeze all layers except the ones we want unfrozen.\n",
    "    \n",
    "\n",
    "In our scenario, we'll freeze all layers except the last 10 layers.\n",
    "\n",
    "Unfreezing only the last 10 layers might seem like the more obvious approach. However, TensorFlow does not currently allow that approach, so we have to follow the above two steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b41960",
   "metadata": {},
   "source": [
    "We managed to get a test accuracy of `~88%` on our `beans` dataset! We didn't have to implement our own architecture, add any regularization, or conduct any hyperparameter optimization, yet we still got a model that performs much better than our previous attempts using transfer learning. However, higher training and validation accuracies, but a relatively lower test accuracy can also be a sign of overfitting. We could always consider adding some regularization to our models to account for that possibility.\n",
    "\n",
    "In this file we learned about:\n",
    "\n",
    "-   Transfer learning and how to implement a workflow for the technique\n",
    "-   Fine-tuning a model that was trained using transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262ad5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = True\n",
    "\n",
    "for layer in base_model.layers[:-10]:\n",
    "    layer.trainable = False\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.00001)\n",
    "loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "model.compile(optimizer=opt, loss=loss, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(b_train_set, epochs=5, validation_data=b_validation_set)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(b_test_set)\n",
    "print(f\"Test set accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb50e04f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
